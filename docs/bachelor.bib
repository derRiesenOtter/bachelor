
@article{alberti_phase_2017,
	title = {Phase separation in biology},
	volume = {27},
	issn = {0960-9822},
	url = {https://www.cell.com/current-biology/abstract/S0960-9822(17)31109-0},
	doi = {10.1016/j.cub.2017.08.069},
	pages = {R1097--R1102},
	number = {20},
	journaltitle = {Current Biology},
	shortjournal = {Current Biology},
	author = {Alberti, Simon},
	urldate = {2025-05-05},
	date = {2017-10-23},
	pmid = {29065286},
	note = {Publisher: Elsevier},
	file = {Full Text PDF:/Users/robin/Zotero/storage/U856B2VH/Alberti - 2017 - Phase separation in biology.pdf:application/pdf},
}

@article{hou_machine_2024,
	title = {Machine learning predictor {PSPire} screens for phase-separating proteins lacking intrinsically disordered regions},
	volume = {15},
	rights = {2024 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-024-46445-y},
	doi = {10.1038/s41467-024-46445-y},
	abstract = {The burgeoning comprehension of protein phase separation ({PS}) has ushered in a wealth of bioinformatics tools for the prediction of phase-separating proteins ({PSPs}). These tools often skew towards {PSPs} with a high content of intrinsically disordered regions ({IDRs}), thus frequently undervaluing potential {PSPs} without {IDRs}. Nonetheless, {PS} is not only steered by {IDRs} but also by the structured modular domains and interactions that aren’t necessarily reflected in amino acid sequences. In this work, we introduce {PSPire}, a machine learning predictor that incorporates both residue-level and structure-level features for the precise prediction of {PSPs}. Compared to current {PSP} predictors, {PSPire} shows a notable improvement in identifying {PSPs} without {IDRs}, which underscores the crucial role of non-{IDR}, structure-based characteristics in multivalent interactions throughout the {PS} process. Additionally, our biological validation experiments substantiate the predictive capacity of {PSPire}, with 9 out of 11 chosen candidate {PSPs} confirmed to form condensates within cells.},
	pages = {2147},
	number = {1},
	journaltitle = {Nature Communications},
	shortjournal = {Nat Commun},
	author = {Hou, Shuang and Hu, Jiaojiao and Yu, Zhaowei and Li, Dan and Liu, Cong and Zhang, Yong},
	urldate = {2025-05-05},
	date = {2024-03-08},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Biophysical chemistry, Computational models, Intrinsically disordered proteins},
	file = {Full Text PDF:/Users/robin/Zotero/storage/IV3RHD2F/Hou et al. - 2024 - Machine learning predictor PSPire screens for phase-separating proteins lacking intrinsically disord.pdf:application/pdf},
}

@online{embl-ebi_what_nodate,
	title = {What are sequence features? {\textbar} Protein classification},
	url = {https://www.ebi.ac.uk/training/online/courses/protein-classification-intro-ebi-resources/protein-classification/what-are-sequence-features/},
	shorttitle = {What are sequence features?},
	abstract = {Protein classification},
	author = {{EMBL}-{EBI}},
	urldate = {2025-05-05},
	langid = {english},
	file = {Snapshot:/Users/robin/Zotero/storage/7FVV87ZJ/what-are-sequence-features.html:text/html},
}

@article{mierlo_predicting_2021,
	title = {Predicting protein condensate formation using machine learning},
	volume = {34},
	issn = {2211-1247},
	url = {https://www.cell.com/cell-reports/abstract/S2211-1247(21)00018-8},
	doi = {10.1016/j.celrep.2021.108705},
	number = {5},
	journaltitle = {Cell Reports},
	shortjournal = {Cell Reports},
	author = {Mierlo, Guido van and Jansen, Jurriaan R. G. and Wang, Jie and Poser, Ina and Heeringen, Simon J. van and Vermeulen, Michiel},
	urldate = {2025-05-06},
	date = {2021-02-02},
	pmid = {33535034},
	note = {Publisher: Elsevier},
	keywords = {condensate formation, machine learning, phase separation},
	file = {Full Text PDF:/Users/robin/Zotero/storage/6L6GYU6Y/Mierlo et al. - 2021 - Predicting protein condensate formation using machine learning.pdf:application/pdf},
}

@article{chen_screening_2022,
	title = {Screening membraneless organelle participants with machine-learning models that integrate multimodal features},
	volume = {119},
	url = {https://www.pnas.org/doi/full/10.1073/pnas.2115369119},
	doi = {10.1073/pnas.2115369119},
	abstract = {Protein self-assembly is one of the formation mechanisms of biomolecular condensates. However, most phase-separating systems ({PS}) demand multiple partners in biological conditions. In this study, we divided {PS} proteins into two groups according to the mechanism by which they undergo {PS}: {PS}-Self proteins can self-assemble spontaneously to form droplets, while {PS}-Part proteins interact with partners to undergo {PS}. Analysis of the amino acid composition revealed differences in the sequence pattern between the two protein groups. Existing {PS} predictors, when evaluated on two test protein sets, preferentially predicted self-assembling proteins. Thus, a comprehensive predictor is required. Herein, we propose that properties other than sequence composition can provide crucial information in screening {PS} proteins. By incorporating phosphorylation frequencies and immunofluorescence image-based droplet-forming propensity with other {PS}-related features, we built two independent machine-learning models to separately predict the two protein categories. Results of independent testing suggested the superiority of integrating multimodal features. We performed experimental verification on the top-scored proteins {DHX}9, Ki-67, and {NIFK}. Their {PS} behavior in vitro revealed the effectiveness of our models in {PS} prediction. Further validation on the proteome of membraneless organelles confirmed the ability of our models to identify {PS}-Part proteins. We implemented a web server named {PhaSePred} (http://predict.phasep.pro/) that incorporates our two models together with representative {PS} predictors. {PhaSePred} displays proteome-level quantiles of different features, thus profiling {PS} propensity and providing crucial information for identification of candidate proteins.},
	pages = {e2115369119},
	number = {24},
	journaltitle = {Proceedings of the National Academy of Sciences},
	author = {Chen, Zhaoming and Hou, Chao and Wang, Liang and Yu, Chunyu and Chen, Taoyu and Shen, Boyan and Hou, Yaoyao and Li, Pilong and Li, Tingting},
	urldate = {2025-05-06},
	date = {2022-06-14},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	file = {Full Text PDF:/Users/robin/Zotero/storage/PBTMEG9S/Chen et al. - 2022 - Screening membraneless organelle participants with machine-learning models that integrate multimodal.pdf:application/pdf},
}

@article{jamialahmadi_artificial_2024,
	title = {Artificial intelligence and bioinformatics: a journey from traditional techniques to smart approaches},
	volume = {17},
	issn = {2008-2258},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11413381/},
	doi = {10.22037/ghfbb.v17i3.2977},
	shorttitle = {Artificial intelligence and bioinformatics},
	abstract = {The incorporation of {AI} models into bioinformatics has brought about a revolutionary era in the analysis and interpretation of biological data. This mini-review offers a succinct overview of the indispensable role {AI} plays in the convergence of computational techniques and biological research. The search strategy followed {PRISMA} guidelines, encompassing databases such as {PubMed}, Embase, and Google Scholar to include studies published between 2018 and 2024, utilizing specific keywords. We explored the diverse applications of {AI} methodologies, including machine learning ({ML}), deep learning ({DL}), and natural language processing ({NLP}), across various domains of bioinformatics. These domains encompass genome sequencing, protein structure prediction, drug discovery, systems biology, personalized medicine, imaging, signal processing, and text mining. {AI} algorithms have exhibited remarkable efficacy in tackling intricate biological challenges, spanning from genome sequencing to protein structure prediction, and from drug discovery to personalized medicine. In conclusion, this study scrutinizes the evolving landscape of {AI}-driven tools and algorithms, emphasizing their pivotal role in expediting research, facilitating data interpretation, and catalyzing innovations in biomedical sciences.},
	pages = {241--252},
	number = {3},
	journaltitle = {Gastroenterology and Hepatology From Bed to Bench},
	shortjournal = {Gastroenterol Hepatol Bed Bench},
	author = {Jamialahmadi, Hamid and Khalili-Tanha, Ghazaleh and Nazari, Elham and Rezaei-Tavirani, Mostafa},
	urldate = {2025-05-07},
	date = {2024},
	pmid = {39308539},
	pmcid = {PMC11413381},
}

@article{jumper_highly_2021,
	title = {Highly accurate protein structure prediction with {AlphaFold}},
	volume = {596},
	rights = {2021 The Author(s)},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-021-03819-2},
	doi = {10.1038/s41586-021-03819-2},
	abstract = {Proteins are essential to life, and understanding their structure can facilitate a mechanistic understanding of their function. Through an enormous experimental effort1–4, the structures of around 100,000 unique proteins have been determined5, but this represents a small fraction of the billions of known protein sequences6,7. Structural coverage is bottlenecked by the months to years of painstaking effort required to determine a single protein structure. Accurate computational approaches are needed to address this gap and to enable large-scale structural bioinformatics. Predicting the three-dimensional structure that a protein will adopt based solely on its amino acid sequence—the structure prediction component of the ‘protein folding problem’8—has been an important open research problem for more than 50 years9. Despite recent progress10–14, existing methods fall far short of atomic accuracy, especially when no homologous structure is available. Here we provide the first computational method that can regularly predict protein structures with atomic accuracy even in cases in which no similar structure is known. We validated an entirely redesigned version of our neural network-based model, {AlphaFold}, in the challenging 14th Critical Assessment of protein Structure Prediction ({CASP}14)15, demonstrating accuracy competitive with experimental structures in a majority of cases and greatly outperforming other methods. Underpinning the latest version of {AlphaFold} is a novel machine learning approach that incorporates physical and biological knowledge about protein structure, leveraging multi-sequence alignments, into the design of the deep learning algorithm.},
	pages = {583--589},
	number = {7873},
	journaltitle = {Nature},
	author = {Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and Žídek, Augustin and Potapenko, Anna and Bridgland, Alex and Meyer, Clemens and Kohl, Simon A. A. and Ballard, Andrew J. and Cowie, Andrew and Romera-Paredes, Bernardino and Nikolov, Stanislav and Jain, Rishub and Adler, Jonas and Back, Trevor and Petersen, Stig and Reiman, David and Clancy, Ellen and Zielinski, Michal and Steinegger, Martin and Pacholska, Michalina and Berghammer, Tamas and Bodenstein, Sebastian and Silver, David and Vinyals, Oriol and Senior, Andrew W. and Kavukcuoglu, Koray and Kohli, Pushmeet and Hassabis, Demis},
	urldate = {2025-05-07},
	date = {2021-08},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Machine learning, Computational biophysics, Protein structure predictions, Structural biology},
	file = {Full Text PDF:/Users/robin/Zotero/storage/SW8Z9P3Q/Jumper et al. - 2021 - Highly accurate protein structure prediction with AlphaFold.pdf:application/pdf},
}

@article{ersavas_novel_2024,
	title = {Novel applications of Convolutional Neural Networks in the age of Transformers},
	volume = {14},
	rights = {2024 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-024-60709-z},
	doi = {10.1038/s41598-024-60709-z},
	abstract = {Convolutional Neural Networks ({CNNs}) have been central to the Deep Learning revolution and played a key role in initiating the new age of Artificial Intelligence. However, in recent years newer architectures such as Transformers have dominated both research and practical applications. While {CNNs} still play critical roles in many of the newer developments such as Generative {AI}, they are far from being thoroughly understood and utilised to their full potential. Here we show that {CNNs} can recognise patterns in images with scattered pixels and can be used to analyse complex datasets by transforming them into pseudo images with minimal processing for any high dimensional dataset, representing a more general approach to the application of {CNNs} to datasets such as in molecular biology, text, and speech. We introduce a pipeline called {DeepMapper}, which allows analysis of very high dimensional datasets without intermediate filtering and dimension reduction, thus preserving the full texture of the data, enabling detection of small variations normally deemed ‘noise’. We demonstrate that {DeepMapper} can identify very small perturbations in large datasets with mostly random variables, and that it is superior in speed and on par in accuracy to prior work in processing large datasets with large numbers of features.},
	pages = {10000},
	number = {1},
	journaltitle = {Scientific Reports},
	shortjournal = {Sci Rep},
	author = {Ersavas, Tansel and Smith, Martin A. and Mattick, John S.},
	urldate = {2025-05-07},
	date = {2024-05-01},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Machine learning, Computational science},
	file = {Full Text PDF:/Users/robin/Zotero/storage/5FRUS2UJ/Ersavas et al. - 2024 - Novel applications of Convolutional Neural Networks in the age of Transformers.pdf:application/pdf},
}

@misc{pintado-grima_confident_2024,
	title = {Confident protein datasets for liquid-liquid phase separation studies},
	url = {https://www.researchsquare.com/article/rs-4594179/v1},
	doi = {10.21203/rs.3.rs-4594179/v1},
	abstract = {Background Proteins self-organize in dynamic cellular environments by assembling into reversible biomolecular condensates through liquid-liquid phase separation ({LLPS}). These condensates can comprise single or multiple proteins, with different roles in the ensemble\&amp;rsquo;s structural and functional integrity. Driver proteins form condensates autonomously, while client proteins just localize within them. Although several databases exist to catalog proteins undergoing {LLPS}, they often contain divergent data that impedes interoperability between these resources. Additionally, there is a lack of consensus on selecting proteins without explicit experimental association with condensates (non-{LLPS} proteins or negative data). These two aspects have prevented the generation of reliable predictive models and fair benchmarks.Results In this work, we used an integrated biocuration protocol to analyze information from all relevant {LLPS} databases and generate confident datasets of client and driver proteins. Besides, we introduce standardized negative datasets, encompassing both globular and disordered proteins. To validate our datasets, we investigated specific physicochemical traits related to {LLPS} across different subsets of protein sequences. We observed significant differences not only between positive and negative instances but also among {LLPS} proteins themselves. The datasets from this study are publicly available as a website at https://llpsdatasets.ppmclab.com and as a data repository at https://github.com/{PPMC}-lab/llps-datasets.Conclusions Our datasets offer a reliable means for confidently assessing the specific roles of proteins in {LLPS} and identifying key differences in physicochemical properties underlying this process. These high-confidence datasets are poised to train a new generation of multilabel models, build more standardized benchmarks, and mitigate sequential biases associated with the presence of intrinsically disordered regions.},
	publisher = {Research Square},
	author = {Pintado-Grima, Carlos and Bárcenas, Oriol and Iglesias, Valentín and Arribas-Ruiz, Eva and Burdukiewicz, Michał and Ventura, Salvador},
	urldate = {2025-06-02},
	date = {2024-07-04},
	note = {{ISSN}: 2693-5015},
	file = {Full Text PDF:/Users/robin/Zotero/storage/AMSFKVZW/Pintado-Grima et al. - 2024 - Confident protein datasets for liquid-liquid phase separation studies.pdf:application/pdf},
}

@article{the_uniprot_consortium_uniprot_2025,
	title = {{UniProt}: the Universal Protein Knowledgebase in 2025},
	volume = {53},
	issn = {1362-4962},
	url = {https://doi.org/10.1093/nar/gkae1010},
	doi = {10.1093/nar/gkae1010},
	shorttitle = {{UniProt}},
	abstract = {The aim of the {UniProt} Knowledgebase ({UniProtKB}; https://www.uniprot.org/) is to provide users with a comprehensive, high-quality and freely accessible set of protein sequences annotated with functional information. In this publication, we describe ongoing changes to our production pipeline to limit the sequences available in {UniProtKB} to high-quality, non-redundant reference proteomes. We continue to manually curate the scientific literature to add the latest functional data and use machine learning techniques. We also encourage community curation to ensure key publications are not missed. We provide an update on the automatic annotation methods used by {UniProtKB} to predict information for unreviewed entries describing unstudied proteins. Finally, updates to the {UniProt} website are described, including a new tab linking protein to genomic information. In recognition of its value to the scientific community, the {UniProt} database has been awarded Global Core Biodata Resource status.},
	pages = {D609--D617},
	issue = {D1},
	journaltitle = {Nucleic Acids Research},
	shortjournal = {Nucleic Acids Research},
	author = {{The UniProt Consortium}},
	urldate = {2025-06-02},
	date = {2025-01-06},
	file = {Full Text PDF:/Users/robin/Zotero/storage/S4KVXP8A/The UniProt Consortium - 2025 - UniProt the Universal Protein Knowledgebase in 2025.pdf:application/pdf;Snapshot:/Users/robin/Zotero/storage/2XQZVMBG/7902999.html:text/html},
}

@article{harris_array_2020,
	title = {Array programming with {NumPy}},
	volume = {585},
	rights = {2020 The Author(s)},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-020-2649-2},
	doi = {10.1038/s41586-020-2649-2},
	abstract = {Array programming provides a powerful, compact and expressive syntax for accessing, manipulating and operating on data in vectors, matrices and higher-dimensional arrays. {NumPy} is the primary array programming library for the Python language. It has an essential role in research analysis pipelines in fields as diverse as physics, chemistry, astronomy, geoscience, biology, psychology, materials science, engineering, finance and economics. For example, in astronomy, {NumPy} was an important part of the software stack used in the discovery of gravitational waves1 and in the first imaging of a black hole2. Here we review how a few fundamental array concepts lead to a simple and powerful programming paradigm for organizing, exploring and analysing scientific data. {NumPy} is the foundation upon which the scientific Python ecosystem is constructed. It is so pervasive that several projects, targeting audiences with specialized needs, have developed their own {NumPy}-like interfaces and array objects. Owing to its central position in the ecosystem, {NumPy} increasingly acts as an interoperability layer between such array computation libraries and, together with its application programming interface ({API}), provides a flexible framework to support the next decade of scientific and industrial analysis.},
	pages = {357--362},
	number = {7825},
	journaltitle = {Nature},
	author = {Harris, Charles R. and Millman, K. Jarrod and van der Walt, Stéfan J. and Gommers, Ralf and Virtanen, Pauli and Cournapeau, David and Wieser, Eric and Taylor, Julian and Berg, Sebastian and Smith, Nathaniel J. and Kern, Robert and Picus, Matti and Hoyer, Stephan and van Kerkwijk, Marten H. and Brett, Matthew and Haldane, Allan and del Río, Jaime Fernández and Wiebe, Mark and Peterson, Pearu and Gérard-Marchant, Pierre and Sheppard, Kevin and Reddy, Tyler and Weckesser, Warren and Abbasi, Hameer and Gohlke, Christoph and Oliphant, Travis E.},
	urldate = {2025-06-02},
	date = {2020-09},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Computational neuroscience, Computational science, Computer science, Software, Solar physics},
	file = {Full Text PDF:/Users/robin/Zotero/storage/LQY34YKQ/Harris et al. - 2020 - Array programming with NumPy.pdf:application/pdf},
}

@article{cock_biopython_2009,
	title = {Biopython: freely available Python tools for computational molecular biology and bioinformatics},
	volume = {25},
	issn = {1367-4803},
	url = {https://doi.org/10.1093/bioinformatics/btp163},
	doi = {10.1093/bioinformatics/btp163},
	shorttitle = {Biopython},
	abstract = {Summary: The Biopython project is a mature open source international collaboration of volunteer developers, providing Python libraries for a wide range of bioinformatics problems. Biopython includes modules for reading and writing different sequence file formats and multiple sequence alignments, dealing with 3D macro molecular structures, interacting with common tools such as {BLAST}, {ClustalW} and {EMBOSS}, accessing key online databases, as well as providing numerical methods for statistical learning.Availability: Biopython is freely available, with documentation and source code at www.biopython.org under the Biopython license.Contact: All queries should be directed to the Biopython mailing lists, see www.biopython.org/wiki/\_Mailing\_listspeter.cock@scri.ac.uk.},
	pages = {1422--1423},
	number = {11},
	journaltitle = {Bioinformatics},
	shortjournal = {Bioinformatics},
	author = {Cock, Peter J. A. and Antao, Tiago and Chang, Jeffrey T. and Chapman, Brad A. and Cox, Cymon J. and Dalke, Andrew and Friedberg, Iddo and Hamelryck, Thomas and Kauff, Frank and Wilczynski, Bartek and de Hoon, Michiel J. L.},
	urldate = {2025-06-02},
	date = {2009-06-01},
	file = {Full Text PDF:/Users/robin/Zotero/storage/GFWKW8SK/Cock et al. - 2009 - Biopython freely available Python tools for computational molecular biology and bioinformatics.pdf:application/pdf;Snapshot:/Users/robin/Zotero/storage/P6YUNB2T/330687.html:text/html},
}

@online{noauthor_pdb-redodssp_nodate,
	title = {{PDB}-{REDO}/dssp: Application to assign secondary structure to proteins},
	url = {https://github.com/PDB-REDO/dssp?tab=readme-ov-file},
	urldate = {2025-06-02},
	file = {PDB-REDO/dssp\: Application to assign secondary structure to proteins:/Users/robin/Zotero/storage/66JIJN9R/dssp.html:text/html},
}

@inproceedings{mckinney_data_2010,
	location = {Austin, Texas},
	title = {Data Structures for Statistical Computing in Python},
	url = {https://doi.curvenote.com/10.25080/Majora-92bf1922-00a},
	doi = {10.25080/Majora-92bf1922-00a},
	abstract = {In this paper we are concerned with the practical issues of working with data sets common to ﬁnance, statistics, and other related ﬁelds. pandas is a new library which aims to facilitate working with these data sets and to provide a set of fundamental building blocks for implementing statistical models. We will discuss speciﬁc design issues encountered in the course of developing pandas with relevant examples and some comparisons with the R language. We conclude by discussing possible future directions for statistical computing and data analysis using Python.},
	eventtitle = {Python in Science Conference},
	pages = {56--61},
	author = {{McKinney}, Wes},
	urldate = {2025-06-02},
	date = {2010},
	langid = {english},
	file = {PDF:/Users/robin/Zotero/storage/AVJ4T92V/McKinney - 2010 - Data Structures for Statistical Computing in Python.pdf:application/pdf},
}

@article{hunter_matplotlib_2007,
	title = {Matplotlib: A 2D Graphics Environment},
	volume = {9},
	issn = {1558-366X},
	url = {https://ieeexplore.ieee.org/document/4160265},
	doi = {10.1109/MCSE.2007.55},
	shorttitle = {Matplotlib},
	abstract = {Matplotlib is a 2D graphics package used for Python for application development, interactive scripting,and publication-quality image generation across user interfaces and operating systems},
	pages = {90--95},
	number = {3},
	journaltitle = {Computing in Science \& Engineering},
	author = {Hunter, John D.},
	urldate = {2025-06-02},
	date = {2007-05},
	keywords = {application development, Computer languages, Equations, Graphical user interfaces, Graphics, Image generation, Interpolation, Operating systems, Packaging, Programming profession, Python, scientific programming, scripting languages, User interfaces},
	file = {Snapshot:/Users/robin/Zotero/storage/KXEZXM5B/4160265.html:text/html},
}

@article{pedregosa_scikit-learn_2011,
	title = {Scikit-learn: Machine Learning in Python},
	volume = {12},
	issn = {1533-7928},
	url = {http://jmlr.org/papers/v12/pedregosa11a.html},
	shorttitle = {Scikit-learn},
	abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language.  Emphasis is put on ease of use, performance, documentation, and {API} consistency.  It has minimal dependencies and is distributed under the simplified {BSD} license, encouraging its use in both academic and commercial settings.  Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
	pages = {2825--2830},
	number = {85},
	journaltitle = {Journal of Machine Learning Research},
	author = {Pedregosa, Fabian and Varoquaux, Gaël and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, Édouard},
	urldate = {2025-06-02},
	date = {2011},
	file = {Full Text PDF:/Users/robin/Zotero/storage/WYLNHNMU/Pedregosa et al. - 2011 - Scikit-learn Machine Learning in Python.pdf:application/pdf},
}

@article{waskom_seaborn_2021,
	title = {seaborn: statistical data visualization},
	volume = {6},
	issn = {2475-9066},
	url = {https://joss.theoj.org/papers/10.21105/joss.03021},
	doi = {10.21105/joss.03021},
	shorttitle = {seaborn},
	abstract = {Waskom, M. L., (2021). seaborn: statistical data visualization. Journal of Open Source Software, 6(60), 3021, https://doi.org/10.21105/joss.03021},
	pages = {3021},
	number = {60},
	journaltitle = {Journal of Open Source Software},
	author = {Waskom, Michael L.},
	urldate = {2025-06-02},
	date = {2021-04-06},
	langid = {english},
	file = {Full Text PDF:/Users/robin/Zotero/storage/DJSRGMPN/Waskom - 2021 - seaborn statistical data visualization.pdf:application/pdf},
}

@online{noauthor_pytorch_nodate,
	title = {{PyTorch} 2 paper and tutorial @ {ASPLOS} 2024 – {PyTorch}},
	url = {https://pytorch.org/blog/pytorch-pytorch-2-paper-tutorial/},
	urldate = {2025-06-02},
	langid = {american},
	file = {Snapshot:/Users/robin/Zotero/storage/243J6H4Q/pytorch-pytorch-2-paper-tutorial.html:text/html},
}

@inproceedings{noauthor_xgboost_nodate,
	title = {{XGBoost}: A Scalable Tree Boosting System},
	url = {https://www.researchgate.net/publication/310824798_XGBoost_A_Scalable_Tree_Boosting_System},
	doi = {10.1145/2939672.2939785},
	shorttitle = {{XGBoost}},
	abstract = {Download Citation {\textbar} {XGBoost}: A Scalable Tree Boosting System {\textbar} Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system... {\textbar} Find, read and cite all the research you need on {ResearchGate}},
	booktitle = {{ResearchGate}},
	urldate = {2025-06-02},
	langid = {english},
	file = {Full Text:/Users/robin/Zotero/storage/KBE6M3IL/XGBoost A Scalable Tree Boosting System.pdf:application/pdf;Snapshot:/Users/robin/Zotero/storage/P6C4SNFV/310824798_XGBoost_A_Scalable_Tree_Boosting_System.html:text/html},
}
