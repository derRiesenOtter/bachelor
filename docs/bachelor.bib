
@article{alberti_phase_2017,
	title = {Phase separation in biology},
	volume = {27},
	issn = {0960-9822},
	url = {https://www.cell.com/current-biology/abstract/S0960-9822(17)31109-0},
	doi = {10.1016/j.cub.2017.08.069},
	pages = {R1097--R1102},
	number = {20},
	journaltitle = {Current Biology},
	shortjournal = {Current Biology},
	author = {Alberti, Simon},
	urldate = {2025-05-05},
	date = {2017-10-23},
	pmid = {29065286},
	note = {Publisher: Elsevier},
	file = {Full Text PDF:/Users/robin/Zotero/storage/U856B2VH/Alberti - 2017 - Phase separation in biology.pdf:application/pdf},
}

@article{hou_machine_2024,
	title = {Machine learning predictor {PSPire} screens for phase-separating proteins lacking intrinsically disordered regions},
	volume = {15},
	rights = {2024 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-024-46445-y},
	doi = {10.1038/s41467-024-46445-y},
	abstract = {The burgeoning comprehension of protein phase separation ({PS}) has ushered in a wealth of bioinformatics tools for the prediction of phase-separating proteins ({PSPs}). These tools often skew towards {PSPs} with a high content of intrinsically disordered regions ({IDRs}), thus frequently undervaluing potential {PSPs} without {IDRs}. Nonetheless, {PS} is not only steered by {IDRs} but also by the structured modular domains and interactions that aren’t necessarily reflected in amino acid sequences. In this work, we introduce {PSPire}, a machine learning predictor that incorporates both residue-level and structure-level features for the precise prediction of {PSPs}. Compared to current {PSP} predictors, {PSPire} shows a notable improvement in identifying {PSPs} without {IDRs}, which underscores the crucial role of non-{IDR}, structure-based characteristics in multivalent interactions throughout the {PS} process. Additionally, our biological validation experiments substantiate the predictive capacity of {PSPire}, with 9 out of 11 chosen candidate {PSPs} confirmed to form condensates within cells.},
	pages = {2147},
	number = {1},
	journaltitle = {Nature Communications},
	shortjournal = {Nat Commun},
	author = {Hou, Shuang and Hu, Jiaojiao and Yu, Zhaowei and Li, Dan and Liu, Cong and Zhang, Yong},
	urldate = {2025-05-05},
	date = {2024-03-08},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Biophysical chemistry, Computational models, Intrinsically disordered proteins},
	file = {Full Text PDF:/Users/robin/Zotero/storage/IV3RHD2F/Hou et al. - 2024 - Machine learning predictor PSPire screens for phase-separating proteins lacking intrinsically disord.pdf:application/pdf},
}

@online{embl-ebi_what_nodate,
	title = {What are sequence features? {\textbar} Protein classification},
	url = {https://www.ebi.ac.uk/training/online/courses/protein-classification-intro-ebi-resources/protein-classification/what-are-sequence-features/},
	shorttitle = {What are sequence features?},
	abstract = {Protein classification},
	author = {{EMBL}-{EBI}},
	urldate = {2025-05-05},
	langid = {english},
	file = {Snapshot:/Users/robin/Zotero/storage/7FVV87ZJ/what-are-sequence-features.html:text/html},
}

@article{mierlo_predicting_2021,
	title = {Predicting protein condensate formation using machine learning},
	volume = {34},
	issn = {2211-1247},
	url = {https://www.cell.com/cell-reports/abstract/S2211-1247(21)00018-8},
	doi = {10.1016/j.celrep.2021.108705},
	number = {5},
	journaltitle = {Cell Reports},
	shortjournal = {Cell Reports},
	author = {Mierlo, Guido van and Jansen, Jurriaan R. G. and Wang, Jie and Poser, Ina and Heeringen, Simon J. van and Vermeulen, Michiel},
	urldate = {2025-05-06},
	date = {2021-02-02},
	pmid = {33535034},
	note = {Publisher: Elsevier},
	keywords = {condensate formation, machine learning, phase separation},
	file = {Full Text PDF:/Users/robin/Zotero/storage/6L6GYU6Y/Mierlo et al. - 2021 - Predicting protein condensate formation using machine learning.pdf:application/pdf},
}

@article{chen_screening_2022,
	title = {Screening membraneless organelle participants with machine-learning models that integrate multimodal features},
	volume = {119},
	url = {https://www.pnas.org/doi/full/10.1073/pnas.2115369119},
	doi = {10.1073/pnas.2115369119},
	abstract = {Protein self-assembly is one of the formation mechanisms of biomolecular condensates. However, most phase-separating systems ({PS}) demand multiple partners in biological conditions. In this study, we divided {PS} proteins into two groups according to the mechanism by which they undergo {PS}: {PS}-Self proteins can self-assemble spontaneously to form droplets, while {PS}-Part proteins interact with partners to undergo {PS}. Analysis of the amino acid composition revealed differences in the sequence pattern between the two protein groups. Existing {PS} predictors, when evaluated on two test protein sets, preferentially predicted self-assembling proteins. Thus, a comprehensive predictor is required. Herein, we propose that properties other than sequence composition can provide crucial information in screening {PS} proteins. By incorporating phosphorylation frequencies and immunofluorescence image-based droplet-forming propensity with other {PS}-related features, we built two independent machine-learning models to separately predict the two protein categories. Results of independent testing suggested the superiority of integrating multimodal features. We performed experimental verification on the top-scored proteins {DHX}9, Ki-67, and {NIFK}. Their {PS} behavior in vitro revealed the effectiveness of our models in {PS} prediction. Further validation on the proteome of membraneless organelles confirmed the ability of our models to identify {PS}-Part proteins. We implemented a web server named {PhaSePred} (http://predict.phasep.pro/) that incorporates our two models together with representative {PS} predictors. {PhaSePred} displays proteome-level quantiles of different features, thus profiling {PS} propensity and providing crucial information for identification of candidate proteins.},
	pages = {e2115369119},
	number = {24},
	journaltitle = {Proceedings of the National Academy of Sciences},
	author = {Chen, Zhaoming and Hou, Chao and Wang, Liang and Yu, Chunyu and Chen, Taoyu and Shen, Boyan and Hou, Yaoyao and Li, Pilong and Li, Tingting},
	urldate = {2025-05-06},
	date = {2022-06-14},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	file = {Full Text PDF:/Users/robin/Zotero/storage/PBTMEG9S/Chen et al. - 2022 - Screening membraneless organelle participants with machine-learning models that integrate multimodal.pdf:application/pdf},
}

@article{jamialahmadi_artificial_2024,
	title = {Artificial intelligence and bioinformatics: a journey from traditional techniques to smart approaches},
	volume = {17},
	issn = {2008-2258},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11413381/},
	doi = {10.22037/ghfbb.v17i3.2977},
	shorttitle = {Artificial intelligence and bioinformatics},
	abstract = {The incorporation of {AI} models into bioinformatics has brought about a revolutionary era in the analysis and interpretation of biological data. This mini-review offers a succinct overview of the indispensable role {AI} plays in the convergence of computational techniques and biological research. The search strategy followed {PRISMA} guidelines, encompassing databases such as {PubMed}, Embase, and Google Scholar to include studies published between 2018 and 2024, utilizing specific keywords. We explored the diverse applications of {AI} methodologies, including machine learning ({ML}), deep learning ({DL}), and natural language processing ({NLP}), across various domains of bioinformatics. These domains encompass genome sequencing, protein structure prediction, drug discovery, systems biology, personalized medicine, imaging, signal processing, and text mining. {AI} algorithms have exhibited remarkable efficacy in tackling intricate biological challenges, spanning from genome sequencing to protein structure prediction, and from drug discovery to personalized medicine. In conclusion, this study scrutinizes the evolving landscape of {AI}-driven tools and algorithms, emphasizing their pivotal role in expediting research, facilitating data interpretation, and catalyzing innovations in biomedical sciences.},
	pages = {241--252},
	number = {3},
	journaltitle = {Gastroenterology and Hepatology From Bed to Bench},
	shortjournal = {Gastroenterol Hepatol Bed Bench},
	author = {Jamialahmadi, Hamid and Khalili-Tanha, Ghazaleh and Nazari, Elham and Rezaei-Tavirani, Mostafa},
	urldate = {2025-05-07},
	date = {2024},
	pmid = {39308539},
	pmcid = {PMC11413381},
}

@article{jumper_highly_2021,
	title = {Highly accurate protein structure prediction with {AlphaFold}},
	volume = {596},
	rights = {2021 The Author(s)},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-021-03819-2},
	doi = {10.1038/s41586-021-03819-2},
	abstract = {Proteins are essential to life, and understanding their structure can facilitate a mechanistic understanding of their function. Through an enormous experimental effort1–4, the structures of around 100,000 unique proteins have been determined5, but this represents a small fraction of the billions of known protein sequences6,7. Structural coverage is bottlenecked by the months to years of painstaking effort required to determine a single protein structure. Accurate computational approaches are needed to address this gap and to enable large-scale structural bioinformatics. Predicting the three-dimensional structure that a protein will adopt based solely on its amino acid sequence—the structure prediction component of the ‘protein folding problem’8—has been an important open research problem for more than 50 years9. Despite recent progress10–14, existing methods fall far short of atomic accuracy, especially when no homologous structure is available. Here we provide the first computational method that can regularly predict protein structures with atomic accuracy even in cases in which no similar structure is known. We validated an entirely redesigned version of our neural network-based model, {AlphaFold}, in the challenging 14th Critical Assessment of protein Structure Prediction ({CASP}14)15, demonstrating accuracy competitive with experimental structures in a majority of cases and greatly outperforming other methods. Underpinning the latest version of {AlphaFold} is a novel machine learning approach that incorporates physical and biological knowledge about protein structure, leveraging multi-sequence alignments, into the design of the deep learning algorithm.},
	pages = {583--589},
	number = {7873},
	journaltitle = {Nature},
	author = {Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and Žídek, Augustin and Potapenko, Anna and Bridgland, Alex and Meyer, Clemens and Kohl, Simon A. A. and Ballard, Andrew J. and Cowie, Andrew and Romera-Paredes, Bernardino and Nikolov, Stanislav and Jain, Rishub and Adler, Jonas and Back, Trevor and Petersen, Stig and Reiman, David and Clancy, Ellen and Zielinski, Michal and Steinegger, Martin and Pacholska, Michalina and Berghammer, Tamas and Bodenstein, Sebastian and Silver, David and Vinyals, Oriol and Senior, Andrew W. and Kavukcuoglu, Koray and Kohli, Pushmeet and Hassabis, Demis},
	urldate = {2025-05-07},
	date = {2021-08},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Computational biophysics, Machine learning, Protein structure predictions, Structural biology},
	file = {Full Text PDF:/Users/robin/Zotero/storage/SW8Z9P3Q/Jumper et al. - 2021 - Highly accurate protein structure prediction with AlphaFold.pdf:application/pdf},
}

@article{ersavas_novel_2024,
	title = {Novel applications of Convolutional Neural Networks in the age of Transformers},
	volume = {14},
	rights = {2024 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-024-60709-z},
	doi = {10.1038/s41598-024-60709-z},
	abstract = {Convolutional Neural Networks ({CNNs}) have been central to the Deep Learning revolution and played a key role in initiating the new age of Artificial Intelligence. However, in recent years newer architectures such as Transformers have dominated both research and practical applications. While {CNNs} still play critical roles in many of the newer developments such as Generative {AI}, they are far from being thoroughly understood and utilised to their full potential. Here we show that {CNNs} can recognise patterns in images with scattered pixels and can be used to analyse complex datasets by transforming them into pseudo images with minimal processing for any high dimensional dataset, representing a more general approach to the application of {CNNs} to datasets such as in molecular biology, text, and speech. We introduce a pipeline called {DeepMapper}, which allows analysis of very high dimensional datasets without intermediate filtering and dimension reduction, thus preserving the full texture of the data, enabling detection of small variations normally deemed ‘noise’. We demonstrate that {DeepMapper} can identify very small perturbations in large datasets with mostly random variables, and that it is superior in speed and on par in accuracy to prior work in processing large datasets with large numbers of features.},
	pages = {10000},
	number = {1},
	journaltitle = {Scientific Reports},
	shortjournal = {Sci Rep},
	author = {Ersavas, Tansel and Smith, Martin A. and Mattick, John S.},
	urldate = {2025-05-07},
	date = {2024-05-01},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Computational science, Machine learning},
	file = {Full Text PDF:/Users/robin/Zotero/storage/5FRUS2UJ/Ersavas et al. - 2024 - Novel applications of Convolutional Neural Networks in the age of Transformers.pdf:application/pdf},
}
